{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob, os\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full database\n",
    "df = pickle.load(open(\"../../../dataResultants/dataset_consolidated.p\", \"rb\"))\n",
    "\n",
    "# # Load metadata\n",
    "# meta = pickle.load(open(\"../../../data/metadata.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we won't be needing\n",
    "df2 = df.copy()\n",
    "\n",
    "df = df.drop(['target','Time','time_seconds'],axis=1)\n",
    "# df will be used for the overlapping window models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data columns and separate them based on the sensor and the feature (accel, vel and magfield)\n",
    "\n",
    "allcols = df.columns.values\n",
    "\n",
    "groupcols = ['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original','time_datetime']\n",
    "waistcols = []\n",
    "ranklecols = []\n",
    "lanklecols = []\n",
    "rthighcols = []\n",
    "lthighcols = []\n",
    "headcols = []\n",
    "sternumcols = []\n",
    "accelcols = []\n",
    "velcols = []\n",
    "magcols = []\n",
    "meancols = []\n",
    "resultantcols = []\n",
    "varcols = []\n",
    "\n",
    "for col in allcols : \n",
    "    if 'r.ankle' in col :\n",
    "        ranklecols.append(col)\n",
    "    if 'l.ankle' in col :\n",
    "        lanklecols.append(col)\n",
    "    if 'waist' in col :\n",
    "        waistcols.append(col)\n",
    "    if 'r.thigh' in col :\n",
    "        rthighcols.append(col)\n",
    "    if 'l.thigh' in col :\n",
    "        lthighcols.append(col)\n",
    "    if 'head' in col :\n",
    "        headcols.append(col)\n",
    "    if 'Velocity' in col :\n",
    "        velcols.append(col)\n",
    "    if 'Magnetic' in col :\n",
    "        magcols.append(col)\n",
    "    if 'Acceleration' in col :\n",
    "        accelcols.append(col)\n",
    "    if 'mean' in col :\n",
    "        meancols.append(col)\n",
    "    if 'var' in col :\n",
    "        varcols.append(col)\n",
    "    if 'resultant' in col :\n",
    "        resultantcols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(resultantcols,axis=1) # Drop the resultant columns from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group in intervals of 0.5 seconds, calculating the mean\n",
    "df_window_mean = df.groupby(['subject','trial_type','trial_subtype','trial_num','trial_num_original',pd.Grouper(key='time_datetime', freq='500000us')]).mean()\n",
    "df_window_mean = df_window_mean.reset_index()\n",
    "\n",
    "# renaming the acceleration measurement columns, including a '_mean' in the end\n",
    "for col in accelcols:\n",
    "    df_window_mean.rename(columns={col: str(col+'_mean')}, inplace=True)\n",
    "\n",
    "for col in velcols:\n",
    "    df_window_mean.rename(columns={col: str(col+'_mean')}, inplace=True)\n",
    "    \n",
    "for col in magcols:\n",
    "    df_window_mean.rename(columns={col: str(col+'_mean')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group in intervals of 2 seconds, calculating the variance\n",
    "\n",
    "df_window_variance = df.groupby(['subject','trial_type','trial_subtype','trial_num','trial_num_original',pd.Grouper(key='time_datetime', freq='500000us')]).var()\n",
    "df_window_variance = df_window_variance.reset_index()\n",
    "\n",
    "# renaming the acceleration measurement columns, including a '_variance' in the end\n",
    "\n",
    "for col in accelcols : \n",
    "    df_window_variance.rename(columns={col: str(col+'_var')}, inplace=True)\n",
    "    \n",
    "for col in velcols : \n",
    "    df_window_variance.rename(columns={col: str(col+'_var')}, inplace=True)\n",
    "    \n",
    "for col in magcols : \n",
    "    df_window_variance.rename(columns={col: str(col+'_var')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe, with all accelerometer columns (means and variances)\n",
    "all_trials_window = pd.merge(df_window_mean, df_window_variance,on=['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original','time_datetime'])\n",
    "\n",
    "# This dataframe will be used in case we decide to try different preprocessing steps\n",
    "all_trials_window = all_trials_window.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data columns and separate them based on the sensor and the feature (accel, vel and magfield)\n",
    "\n",
    "allcols = all_trials_window.columns.values\n",
    "\n",
    "groupcols = ['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original']\n",
    "waistcols = []\n",
    "ranklecols = []\n",
    "lanklecols = []\n",
    "rthighcols = []\n",
    "lthighcols = []\n",
    "headcols = []\n",
    "sternumcols = []\n",
    "accelcols = []\n",
    "velcols = []\n",
    "magcols = []\n",
    "meancols = []\n",
    "varcols = []\n",
    "\n",
    "for col in allcols : \n",
    "    if 'r.ankle' in col :\n",
    "        ranklecols.append(col)\n",
    "    if 'l.ankle' in col :\n",
    "        lanklecols.append(col)\n",
    "    if 'waist' in col :\n",
    "        waistcols.append(col)\n",
    "    if 'r.thigh' in col :\n",
    "        rthighcols.append(col)\n",
    "    if 'l.thigh' in col :\n",
    "        lthighcols.append(col)\n",
    "    if 'head' in col :\n",
    "        headcols.append(col)\n",
    "    if 'Velocity' in col :\n",
    "        velcols.append(col)\n",
    "    if 'Magnetic' in col :\n",
    "        magcols.append(col)\n",
    "    if 'Acceleration' in col :\n",
    "        accelcols.append(col)\n",
    "    if 'mean' in col :\n",
    "        meancols.append(col)\n",
    "    if 'var' in col :\n",
    "        varcols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping windows around axis acceleration peaks\n",
    "#### First we find the biggest peak in each acceleration axis (be it a maximum or minimum peak) and we create a window that spans from the smallest peak-1 second to the biggest peak + 1 second. This creates a window that takes into account all 3 peaks. \n",
    "#### We'll be using only the waist for these tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just waist acceleration columns, time and groupcols\n",
    "dfWaistAccels = all_trials_window[['time_datetime']+groupcols + list(set(accelcols) & set(waistcols))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auxdf = dfWaistAccels\n",
    "\n",
    "# Add absolute value of the acceleration means as new columns to auxdf\n",
    "auxdf['AbsX'] = auxdf['waist Acceleration X (m/s^2)_mean'].abs()\n",
    "auxdf['AbsY'] = auxdf['waist Acceleration Y (m/s^2)_mean'].abs()\n",
    "auxdf['AbsZ'] = auxdf['waist Acceleration Z (m/s^2)_mean'].abs()\n",
    "\n",
    "# Find the id of the rows with max absolute value for each axis\n",
    "dfWaistAccels['YMax'] = auxdf.groupby(groupcols)['AbsY'].transform('idxmax')\n",
    "dfWaistAccels['XMax'] = auxdf.groupby(groupcols)['AbsX'].transform('idxmax')\n",
    "dfWaistAccels['ZMax'] = auxdf.groupby(groupcols)['AbsZ'].transform('idxmax')\n",
    "\n",
    "# Find the max and min ids from the last section\n",
    "dfWaistAccels['AxisMax'] = dfWaistAccels[[\"YMax\", \"XMax\",\"ZMax\"]].max(axis=1)\n",
    "dfWaistAccels['AxisMin'] = dfWaistAccels[[\"YMax\", \"XMax\",\"ZMax\"]].min(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the window for each subject,trialtype, subtype and number and combine them all into one single dataframe\n",
    "dfList = []\n",
    "for sub in dfWaistAccels['subject'].unique() :\n",
    "    for trialtype in dfWaistAccels['trial_type'].unique() :\n",
    "        for subtype in dfWaistAccels['trial_subtype'].unique() :\n",
    "            for num in dfWaistAccels['trial_num'].unique() :\n",
    "                aux1 = dfWaistAccels[(dfWaistAccels['subject'] == sub) & (dfWaistAccels['trial_type'] == trialtype) \n",
    "                    & (dfWaistAccels['trial_subtype'] == subtype) & (dfWaistAccels['trial_num'] == num)]\n",
    "                aux2 = aux1[(aux1.index < aux1.AxisMax+2) & (aux1.index > aux1.AxisMin-2)]\n",
    "                dfList.append(aux2)\n",
    "\n",
    "fulldf = pd.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns we don't need anymore\n",
    "fulldf = fulldf.drop(['XMax','ZMax','YMax','AxisMax','AxisMin','AbsX','AbsY','AbsZ'],axis=1)\n",
    "\n",
    "# Adding a target column\n",
    "def generateTarget(row) :\n",
    "    if row['trial_type'] == 'ADLs' :\n",
    "        return 0\n",
    "    if row['trial_type'] == 'Near_Falls' :\n",
    "        return 0\n",
    "    if row['trial_type'] == 'Falls' :\n",
    "        return 1\n",
    "    \n",
    "fulldf['target'] = fulldf.apply (lambda row: generateTarget(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use this function to test our models from now on\n",
    "def modelProcessing(X_train,y_train,X_test,y_test,model) :\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy : \"+str(accuracy_score(y_test,y_pred)))\n",
    "    print(\"Recall : \" +str(recall_score(y_test,y_pred)))\n",
    "    print(\"Precision : \"+str(precision_score(y_test,y_pred)))\n",
    "    print(\"F-measure :\"+str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all variance and mean columns to predict and subjects 6-10 to train, 1-5 to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.780831914376\n",
      "Recall : 0.414669571532\n",
      "Precision : 0.857357357357\n",
      "F-measure :0.558981889378\n"
     ]
    }
   ],
   "source": [
    "y_train = fulldf[(fulldf['subject'] >= 6)]['target']\n",
    "X_train = fulldf[(fulldf['subject'] >= 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "y_test = fulldf[(fulldf['subject'] < 6)]['target']\n",
    "X_test = fulldf[(fulldf['subject'] < 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', cache_size=500000, coef0=0, C=1, gamma=0.01,  class_weight=None)\n",
    "modelProcessing(X_train,y_train,X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only mean columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.778156166383\n",
      "Recall : 0.366739288308\n",
      "Precision : 0.926605504587\n",
      "F-measure :0.525494276795\n"
     ]
    }
   ],
   "source": [
    "y_train = fulldf[(fulldf['subject'] >= 6)]['target']\n",
    "X_train = fulldf[(fulldf['subject'] >= 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "X_train = X_train.drop(['waist Acceleration X (m/s^2)_var','waist Acceleration Y (m/s^2)_var',\n",
    "                        'waist Acceleration Z (m/s^2)_var'],axis=1)\n",
    "y_test = fulldf[(fulldf['subject'] < 6)]['target']\n",
    "X_test = fulldf[(fulldf['subject'] < 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "X_test = X_test.drop(['waist Acceleration X (m/s^2)_var','waist Acceleration Y (m/s^2)_var',\n",
    "                        'waist Acceleration Z (m/s^2)_var'],axis=1)\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', cache_size=500000, coef0=0, C=1, gamma=0.01,  class_weight=None)\n",
    "modelProcessing(X_train,y_train,X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultant peak windows :\n",
    "## Without making smaller windows first\n",
    "#### Only with waist and acceleration for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a target column\n",
    "def generateTarget2(row) :\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just waist acceleration columns, time and groupcols\n",
    "# print(resultantcols)\n",
    "resultantwaist = []\n",
    "for col in resultantcols :\n",
    "    if (\"waist\" in col) & (\"acceleration\" in col) :\n",
    "        resultantwaist.append(col)\n",
    "accelcols = []\n",
    "waistcols = []\n",
    "for col in df2.columns.values :\n",
    "    if (\"Acceleration\" in col) :\n",
    "        accelcols.append(col)\n",
    "    if (\"waist\" in col) :\n",
    "        waistcols.append(col)\n",
    "    \n",
    "df2WaistResultant = df2[['time_seconds']+groupcols + resultantwaist + list(set(accelcols) & set(waistcols))]\n",
    "df2WaistResultant['target'] = df2WaistResultant.apply(lambda row: generateTarget2(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 128 times 0.00781 is approx 1 second.\n",
    "# Meaning i need 256 rows up and 256 rows down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the window for each subject,trialtype, subtype and number and combine them all into one single dataframe\n",
    "df2List = []\n",
    "for sub in df2WaistResultant['subject'].unique() :\n",
    "    for trialtype in ['Falls'] :\n",
    "        for subtype in df2WaistResultant['trial_subtype'].unique() :\n",
    "            for num in df2WaistResultant['trial_num'].unique() :\n",
    "                aux1 = df2WaistResultant[(df2WaistResultant['subject'] == sub) & \n",
    "                                         (df2WaistResultant['trial_type'] == trialtype) & \n",
    "                                         (df2WaistResultant['trial_subtype'] == subtype) & \n",
    "                                         (df2WaistResultant['trial_num'] == num)]\n",
    "                if (aux1.shape[0] > 0) :\n",
    "                    peak_index = aux1['waist resultant acceleration'].idxmax()\n",
    "#                     time_peak = aux1.iloc[peak_index,aux1.columns.get_loc('time_seconds')]\n",
    "#                     aux2 = aux1[(aux1.index < peak_index+2) & (aux1.index > peak_index-2)]\n",
    "                    for i in range(peak_index-256,peak_index+256) : # Add the target 1 to the window\n",
    "                        aux1.set_value(i, 'target', 1)\n",
    "                    df2List.append(aux1)\n",
    "\n",
    "fulldf2 = pd.concat(df2List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS PART OF THE CODE CAUSES THE KERNEL TO STOP AND RESTART\n",
    "y_train = fulldf2[(fulldf2['subject'] >= 9)]['target']\n",
    "X_train = fulldf2[(fulldf2['subject'] >= 9)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype','waist resultant acceleration', \n",
    "                    'trial_num', 'time_seconds','target','time_datetime'],axis=1)\n",
    "\n",
    "y_test = fulldf2[(fulldf2['subject'] < 2)]['target']\n",
    "X_test = fulldf2[(fulldf2['subject'] < 2)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype','waist resultant acceleration', \n",
    "                    'trial_num', 'time_seconds','target','time_datetime'],axis=1)\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', cache_size=500000, coef0=0, C=1, gamma=0.01,  class_weight=None)\n",
    "modelProcessing(X_train,y_train,X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
