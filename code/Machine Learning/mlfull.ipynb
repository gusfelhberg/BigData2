{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob, os\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "# Adding a target column\n",
    "def generateTarget(row) :\n",
    "    if row['trial_type'] == 'ADLs' :\n",
    "        return 0\n",
    "    if row['trial_type'] == 'Near_Falls' :\n",
    "        return 0\n",
    "    if row['trial_type'] == 'Falls' :\n",
    "        return 1\n",
    "    \n",
    "# Adding a target column\n",
    "def generateTarget2(row) :\n",
    "    return 0\n",
    "\n",
    "# We'll use this function to test our models from now on\n",
    "def modelProcessing(X_train,y_train,X_test,y_test,model) :\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy : \"+str(accuracy_score(y_test,y_pred)))\n",
    "    print(\"Recall : \" +str(recall_score(y_test,y_pred)))\n",
    "    print(\"Precision : \"+str(precision_score(y_test,y_pred)))\n",
    "    print(\"F-measure :\"+str(f1_score(y_test,y_pred)))\n",
    "\n",
    "# Obtain a DF with the metrics and bodyparts you want\n",
    "def filterCols(df,metrics,bodyparts,resultants=True) :\n",
    "    # Metrics are Acceleration,Magnetic and Velocity (List of strings)\n",
    "    # Bodyparts are waist,l.ankle,r.ankle,l.thigh,r.thigh,sternum,head (list of strings)\n",
    "    # Resultants = true will get the resultants of the respective metrics\n",
    "    groupcols = ['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original','time_datetime']\n",
    "    metriccols = []\n",
    "    bodycols = []\n",
    "    \n",
    "    for col in df.columns.values :\n",
    "        for metric in metrics :\n",
    "            if (metric in col) :\n",
    "                metriccols.append(col)\n",
    "            if (resultants) :\n",
    "                if (metric.lower() in col) :\n",
    "                    metriccols.append(col)\n",
    "        for part in bodyparts :\n",
    "            if (part in col) :\n",
    "                bodycols.append(col)\n",
    "    dfOut = df[groupcols + list(set(metriccols) & set(bodycols))]\n",
    "    return dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full database\n",
    "df = pickle.load(open(\"../../../dataResultants/dataset_consolidated.p\", \"rb\"))\n",
    "\n",
    "# # Load metadata\n",
    "# meta = pickle.load(open(\"../../../data/metadata.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we won't be needing\n",
    "df2 = df.copy()\n",
    "df2 = df2.drop(['target','Time','time_seconds'],axis=1)\n",
    "df = df.drop(['target','Time','time_seconds'],axis=1)\n",
    "# df will be used for the overlapping window models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data columns and separate them based on the sensor and the feature (accel, vel and magfield)\n",
    "\n",
    "allcols = df.columns.values\n",
    "\n",
    "groupcols = ['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original','time_datetime']\n",
    "waistcols = []\n",
    "ranklecols = []\n",
    "lanklecols = []\n",
    "rthighcols = []\n",
    "lthighcols = []\n",
    "headcols = []\n",
    "sternumcols = []\n",
    "accelcols = []\n",
    "velcols = []\n",
    "magcols = []\n",
    "meancols = []\n",
    "resultantcols = []\n",
    "varcols = []\n",
    "\n",
    "for col in allcols : \n",
    "    if 'r.ankle' in col :\n",
    "        ranklecols.append(col)\n",
    "    if 'l.ankle' in col :\n",
    "        lanklecols.append(col)\n",
    "    if 'waist' in col :\n",
    "        waistcols.append(col)\n",
    "    if 'r.thigh' in col :\n",
    "        rthighcols.append(col)\n",
    "    if 'l.thigh' in col :\n",
    "        lthighcols.append(col)\n",
    "    if 'head' in col :\n",
    "        headcols.append(col)\n",
    "    if 'Velocity' in col :\n",
    "        velcols.append(col)\n",
    "    if 'Magnetic' in col :\n",
    "        magcols.append(col)\n",
    "    if 'Acceleration' in col :\n",
    "        accelcols.append(col)\n",
    "    if 'mean' in col :\n",
    "        meancols.append(col)\n",
    "    if 'var' in col :\n",
    "        varcols.append(col)\n",
    "    if 'resultant' in col :\n",
    "        resultantcols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(resultantcols,axis=1) # Drop the resultant columns from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group in intervals of 0.5 seconds, calculating the mean\n",
    "df_window_mean = df.groupby(['subject','trial_type','trial_subtype','trial_num','trial_num_original',pd.Grouper(key='time_datetime', freq='500000us')]).mean()\n",
    "df_window_mean = df_window_mean.reset_index()\n",
    "\n",
    "# renaming the acceleration measurement columns, including a '_mean' in the end\n",
    "for col in accelcols:\n",
    "    df_window_mean.rename(columns={col: str(col+'_mean')}, inplace=True)\n",
    "\n",
    "for col in velcols:\n",
    "    df_window_mean.rename(columns={col: str(col+'_mean')}, inplace=True)\n",
    "    \n",
    "for col in magcols:\n",
    "    df_window_mean.rename(columns={col: str(col+'_mean')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group in intervals of 2 seconds, calculating the variance\n",
    "\n",
    "df_window_variance = df.groupby(['subject','trial_type','trial_subtype','trial_num','trial_num_original',pd.Grouper(key='time_datetime', freq='500000us')]).var()\n",
    "df_window_variance = df_window_variance.reset_index()\n",
    "\n",
    "# renaming the acceleration measurement columns, including a '_variance' in the end\n",
    "\n",
    "for col in accelcols : \n",
    "    df_window_variance.rename(columns={col: str(col+'_var')}, inplace=True)\n",
    "    \n",
    "for col in velcols : \n",
    "    df_window_variance.rename(columns={col: str(col+'_var')}, inplace=True)\n",
    "    \n",
    "for col in magcols : \n",
    "    df_window_variance.rename(columns={col: str(col+'_var')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe, with all accelerometer columns (means and variances)\n",
    "all_trials_window = pd.merge(df_window_mean, df_window_variance,on=['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original','time_datetime'])\n",
    "\n",
    "# This dataframe will be used in case we decide to try different preprocessing steps\n",
    "all_trials_window = all_trials_window.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data columns and separate them based on the sensor and the feature (accel, vel and magfield)\n",
    "\n",
    "allcols = all_trials_window.columns.values\n",
    "\n",
    "groupcols = ['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original']\n",
    "waistcols = []\n",
    "ranklecols = []\n",
    "lanklecols = []\n",
    "rthighcols = []\n",
    "lthighcols = []\n",
    "headcols = []\n",
    "sternumcols = []\n",
    "accelcols = []\n",
    "velcols = []\n",
    "magcols = []\n",
    "meancols = []\n",
    "varcols = []\n",
    "\n",
    "for col in allcols : \n",
    "    if 'r.ankle' in col :\n",
    "        ranklecols.append(col)\n",
    "    if 'l.ankle' in col :\n",
    "        lanklecols.append(col)\n",
    "    if 'waist' in col :\n",
    "        waistcols.append(col)\n",
    "    if 'r.thigh' in col :\n",
    "        rthighcols.append(col)\n",
    "    if 'l.thigh' in col :\n",
    "        lthighcols.append(col)\n",
    "    if 'head' in col :\n",
    "        headcols.append(col)\n",
    "    if 'Velocity' in col :\n",
    "        velcols.append(col)\n",
    "    if 'Magnetic' in col :\n",
    "        magcols.append(col)\n",
    "    if 'Acceleration' in col :\n",
    "        accelcols.append(col)\n",
    "    if 'mean' in col :\n",
    "        meancols.append(col)\n",
    "    if 'var' in col :\n",
    "        varcols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping windows around axis acceleration peaks\n",
    "#### First we find the biggest peak in each acceleration axis (be it a maximum or minimum peak) and we create a window that spans from the smallest peak-1 second to the biggest peak + 1 second. This creates a window that takes into account all 3 peaks. \n",
    "#### We'll be using only the waist for these tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject' 'trial_type' 'trial_subtype' 'trial_num' 'trial_num_original'\n",
      " 'time_datetime' 'waist Acceleration Z (m/s^2)_var'\n",
      " 'waist Acceleration X (m/s^2)_var' 'waist Acceleration Z (m/s^2)_mean'\n",
      " 'waist Acceleration X (m/s^2)_mean' 'waist Acceleration Y (m/s^2)_var'\n",
      " 'waist Acceleration Y (m/s^2)_mean']\n"
     ]
    }
   ],
   "source": [
    "# Get just waist acceleration columns, time and groupcols\n",
    "dfWaistAccels = filterCols(all_trials_window,['Acceleration'],['waist'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auxdf = dfWaistAccels\n",
    "\n",
    "# Add absolute value of the acceleration means as new columns to auxdf\n",
    "auxdf['AbsX'] = auxdf['waist Acceleration X (m/s^2)_mean'].abs()\n",
    "auxdf['AbsY'] = auxdf['waist Acceleration Y (m/s^2)_mean'].abs()\n",
    "auxdf['AbsZ'] = auxdf['waist Acceleration Z (m/s^2)_mean'].abs()\n",
    "\n",
    "# Find the id of the rows with max absolute value for each axis\n",
    "dfWaistAccels['YMax'] = auxdf.groupby(groupcols)['AbsY'].transform('idxmax')\n",
    "dfWaistAccels['XMax'] = auxdf.groupby(groupcols)['AbsX'].transform('idxmax')\n",
    "dfWaistAccels['ZMax'] = auxdf.groupby(groupcols)['AbsZ'].transform('idxmax')\n",
    "\n",
    "# Find the max and min ids from the last section\n",
    "dfWaistAccels['AxisMax'] = dfWaistAccels[[\"YMax\", \"XMax\",\"ZMax\"]].max(axis=1)\n",
    "dfWaistAccels['AxisMin'] = dfWaistAccels[[\"YMax\", \"XMax\",\"ZMax\"]].min(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the window for each subject,trialtype, subtype and number and combine them all into one single dataframe\n",
    "dfList = []\n",
    "for sub in dfWaistAccels['subject'].unique() :\n",
    "    for trialtype in dfWaistAccels['trial_type'].unique() :\n",
    "        for subtype in dfWaistAccels['trial_subtype'].unique() :\n",
    "            for num in dfWaistAccels['trial_num'].unique() :\n",
    "                aux1 = dfWaistAccels[(dfWaistAccels['subject'] == sub) & (dfWaistAccels['trial_type'] == trialtype) \n",
    "                    & (dfWaistAccels['trial_subtype'] == subtype) & (dfWaistAccels['trial_num'] == num)]\n",
    "                aux2 = aux1[(aux1.index < aux1.AxisMax+2) & (aux1.index > aux1.AxisMin-2)]\n",
    "                dfList.append(aux2)\n",
    "\n",
    "fulldf = pd.concat(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns we don't need anymore\n",
    "fulldf = fulldf.drop(['XMax','ZMax','YMax','AxisMax','AxisMin','AbsX','AbsY','AbsZ'],axis=1)\n",
    "    \n",
    "fulldf['target'] = fulldf.apply (lambda row: generateTarget(row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all variance and mean columns to predict and subjects 6-10 to train, 1-5 to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.780831914376\n",
      "Recall : 0.414669571532\n",
      "Precision : 0.857357357357\n",
      "F-measure :0.558981889378\n"
     ]
    }
   ],
   "source": [
    "y_train = fulldf[(fulldf['subject'] >= 6)]['target']\n",
    "X_train = fulldf[(fulldf['subject'] >= 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "y_test = fulldf[(fulldf['subject'] < 6)]['target']\n",
    "X_test = fulldf[(fulldf['subject'] < 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', cache_size=500000, coef0=0, C=1, gamma=0.01,  class_weight=None)\n",
    "modelProcessing(X_train,y_train,X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only mean columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.778156166383\n",
      "Recall : 0.366739288308\n",
      "Precision : 0.926605504587\n",
      "F-measure :0.525494276795\n"
     ]
    }
   ],
   "source": [
    "y_train = fulldf[(fulldf['subject'] >= 6)]['target']\n",
    "X_train = fulldf[(fulldf['subject'] >= 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "X_train = X_train.drop(['waist Acceleration X (m/s^2)_var','waist Acceleration Y (m/s^2)_var',\n",
    "                        'waist Acceleration Z (m/s^2)_var'],axis=1)\n",
    "y_test = fulldf[(fulldf['subject'] < 6)]['target']\n",
    "X_test = fulldf[(fulldf['subject'] < 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', 'trial_num', 'time_datetime','target'],axis=1)\n",
    "X_test = X_test.drop(['waist Acceleration X (m/s^2)_var','waist Acceleration Y (m/s^2)_var',\n",
    "                        'waist Acceleration Z (m/s^2)_var'],axis=1)\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', cache_size=500000, coef0=0, C=1, gamma=0.01,  class_weight=None)\n",
    "modelProcessing(X_train,y_train,X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultant peak windows :\n",
    "## Without making smaller windows first\n",
    "#### Only with waist and acceleration for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group in intervals of 0.5 seconds, calculating the mean\n",
    "df2_window_mean = df2.groupby(['subject','trial_type','trial_subtype','trial_num','trial_num_original',pd.Grouper(key='time_datetime', freq='500000us')]).mean()\n",
    "df2_window_mean = df2_window_mean.reset_index()\n",
    "\n",
    "# renaming the acceleration measurement columns, including a '_mean' in the end\n",
    "for col in df2.columns.values :\n",
    "    if ('Acceleration' in col) or ('Velocity' in col) or ('Magnetic' in col) or ('resultant' in col) :\n",
    "        df2_window_mean.rename(columns={col: str(col+'_mean')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group in intervals of 2 seconds, calculating the variance\n",
    "\n",
    "df2_window_variance = df2.groupby(['subject','trial_type','trial_subtype','trial_num','trial_num_original',pd.Grouper(key='time_datetime', freq='500000us')]).var()\n",
    "df2_window_variance = df2_window_variance.reset_index()\n",
    "\n",
    "# renaming the acceleration measurement columns, including a '_variance' in the end\n",
    "for col in df2.columns.values :\n",
    "    if ('Acceleration' in col) or ('Velocity' in col) or ('Magnetic' in col) or ('resultant' in col) :\n",
    "        df2_window_variance.rename(columns={col: str(col+'_var')}, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataframe, with all accelerometer columns (means and variances)\n",
    "df2_all_windows = pd.merge(df2_window_mean, df2_window_variance,on=['subject', 'trial_type', 'trial_subtype', 'trial_num','trial_num_original','time_datetime'])\n",
    "\n",
    "# This dataframe will be used in case we decide to try different preprocessing steps\n",
    "df2_all_windows = df2_all_windows.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject' 'trial_type' 'trial_subtype' 'trial_num' 'trial_num_original'\n",
      " 'time_datetime' 'waist Acceleration Z (m/s^2)_var'\n",
      " 'head Acceleration Y (m/s^2)_mean' 'head resultant acceleration_mean'\n",
      " 'head Acceleration X (m/s^2)_mean' 'head Acceleration X (m/s^2)_var'\n",
      " 'waist Acceleration X (m/s^2)_var' 'waist Acceleration Z (m/s^2)_mean'\n",
      " 'head Acceleration Z (m/s^2)_mean' 'head resultant acceleration_var'\n",
      " 'waist resultant acceleration_var' 'head Acceleration Z (m/s^2)_var'\n",
      " 'waist resultant acceleration_mean' 'waist Acceleration X (m/s^2)_mean'\n",
      " 'head Acceleration Y (m/s^2)_var' 'waist Acceleration Y (m/s^2)_var'\n",
      " 'waist Acceleration Y (m/s^2)_mean' 'target']\n"
     ]
    }
   ],
   "source": [
    "dfResWindows = filterCols(df2_all_windows,['Acceleration'],['head','waist'],True)\n",
    "dfResWindows['target'] = dfResWindows.apply(lambda row: generateTarget2(row),axis=1)\n",
    "print(dfResWindows.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the window for each subject,trialtype, subtype and number and combine them all into one single dataframe\n",
    "df2List = []\n",
    "for sub in dfResWindows['subject'].unique() :\n",
    "    for trialtype in ['Falls'] :\n",
    "        for subtype in dfResWindows['trial_subtype'].unique() :\n",
    "            for num in dfResWindows['trial_num'].unique() :\n",
    "                aux1 = dfResWindows[(dfResWindows['subject'] == sub) & \n",
    "                                         (dfResWindows['trial_type'] == trialtype) & \n",
    "                                         (dfResWindows['trial_subtype'] == subtype) & \n",
    "                                         (dfResWindows['trial_num'] == num)]\n",
    "                if (aux1.shape[0] > 0) :\n",
    "                    peak_index = aux1['waist resultant acceleration_mean'].idxmax()\n",
    "#                     time_peak = aux1.iloc[peak_index,aux1.columns.get_loc('time_seconds')]\n",
    "#                     aux2 = aux1[(aux1.index < peak_index+2) & (aux1.index > peak_index-2)]\n",
    "                    for i in range(peak_index-4,peak_index+4) : # Add the target 1 to the window\n",
    "                        aux1.set_value(i, 'target', 1)\n",
    "                    df2List.append(aux1)\n",
    "\n",
    "fulldf2 = pd.concat(df2List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.864041833282\n",
      "Recall : 0.644047619048\n",
      "Precision : 0.790935672515\n",
      "F-measure :0.709973753281\n"
     ]
    }
   ],
   "source": [
    "y_train = fulldf2[(fulldf2['subject'] >= 6)]['target']\n",
    "X_train = fulldf2[(fulldf2['subject'] >= 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', \n",
    "                    'trial_num','target','time_datetime'],axis=1)\n",
    "\n",
    "y_test = fulldf2[(fulldf2['subject'] < 6)]['target']\n",
    "X_test = fulldf2[(fulldf2['subject'] < 6)].drop(['trial_num_original',\n",
    "                'trial_type', 'subject', 'trial_subtype', \n",
    "                    'trial_num','target','time_datetime'],axis=1)\n",
    "\n",
    "clf = svm.SVC(decision_function_shape='ovo', cache_size=500000, coef0=0, C=1, gamma=0.01,  class_weight=None)\n",
    "modelProcessing(X_train,y_train,X_test,y_test,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------\n",
    "# Waist with each Metric : \n",
    "# [Waist],[Acceleration],Resultants :\n",
    "# Accuracy : 0.870808981852\n",
    "# Recall : 0.592857142857\n",
    "# Precision : 0.864583333333\n",
    "# F-measure :0.703389830508\n",
    "\n",
    "# [Waist],[Velocity],Resultants : // Window around waist resultant velocity\n",
    "# Accuracy : 0.834204860043\n",
    "# Recall : 0.375\n",
    "# Precision : 0.957446808511\n",
    "# F-measure :0.538922155689\n",
    "\n",
    "# [Waist],[Acceleration,Velocity],Resultants : // Acceleration seems to dominate Velocity?\n",
    "# Accuracy : 0.870808981852\n",
    "# Recall : 0.589285714286\n",
    "# Precision : 0.868421052632\n",
    "# F-measure :0.702127659574\n",
    "\n",
    "# [Waist],[Acceleration,Velocity,Magnetic],Resultants : // Conclusion : Magnetic field is USELESS\n",
    "# Accuracy : 0.665333743464\n",
    "# Recall : 0.779761904762\n",
    "# Precision : 0.420410783055\n",
    "# F-measure :0.546288573812\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "\n",
    "# [Waist,Lthigh,Rthigh],[Acceleration], Resultants :\n",
    "# Accuracy : 0.876345739772\n",
    "# Recall : 0.72619047619\n",
    "# Precision : 0.780051150895\n",
    "# F-measure :0.75215782984\n",
    "\n",
    "# [Waist,Sternum],[Acceleration],Resultants :\n",
    "# Accuracy : 0.860043063673\n",
    "# Recall : 0.641666666667\n",
    "# Precision : 0.777777777778\n",
    "# F-measure :0.703196347032\n",
    "\n",
    "# [Sternum],[Acceleration],Resultants :  // Window around sternum resultant acceleration\n",
    "# Accuracy : 0.864041833282\n",
    "# Recall : 0.559523809524\n",
    "# Precision : 0.867158671587\n",
    "# F-measure :0.68017366136\n",
    "\n",
    "# [AllbodyParts],[Acceleration],Resultants : \n",
    "# Accuracy : 0.80375269148\n",
    "# Recall : 0.805952380952\n",
    "# Precision : 0.587673611111\n",
    "# F-measure :0.679718875502\n",
    "\n",
    "# [Head,Sternum,Waist],[Acceleration],Resultants :\n",
    "# Accuracy : 0.860350661335\n",
    "# Recall : 0.669047619048\n",
    "# Precision : 0.761517615176\n",
    "# F-measure :0.712294043093\n",
    "\n",
    "# [Head,Sternum,Waist],[Acceleration],Resultants : // Window around the head resultant acceleration\n",
    "# Accuracy : 0.855736696401\n",
    "# Recall : 0.671428571429\n",
    "# Precision : 0.745046235139\n",
    "# F-measure :0.706324358172\n",
    "\n",
    "# [Head,Sternum,Waist],[Acceleration],Resultants : // Window around the sternum resultant acceleration\n",
    "# Accuracy : 0.849892340818\n",
    "# Recall : 0.675\n",
    "# Precision : 0.725063938619\n",
    "# F-measure :0.699136868064\n",
    "\n",
    "# [L.thigh],[Acceleration],Resultants : // Window around l.thigh resultant acceleration\n",
    "# Accuracy : 0.872962165488\n",
    "# Recall : 0.644391408115\n",
    "# Precision : 0.824427480916\n",
    "# F-measure :0.723375753516\n",
    "\n",
    "# [R.thigh],[Acceleration],Resultants : // Window around R.thigh resultant acceleration\n",
    "# Accuracy : 0.868963395878\n",
    "# Recall : 0.621266427718\n",
    "# Precision : 0.826709062003\n",
    "# F-measure :0.709413369714\n",
    "\n",
    "# [Waist, L.ankle,R.ankle],[Acceleration],Resultants :\n",
    "# Accuracy : 0.816671793294\n",
    "# Recall : 0.752380952381\n",
    "# Precision : 0.619607843137\n",
    "# F-measure :0.679569892473\n",
    "\n",
    "# Some thoughts :\n",
    "# Magnetic field appearsto be useless\n",
    "# Waist is the most useful centor, followed by thighs, head and sternum. Ankles aren't super useful\n",
    "# Velocity doesn't do much, most likely because it's so linked with acceleration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
